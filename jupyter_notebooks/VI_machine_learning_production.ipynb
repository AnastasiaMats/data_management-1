{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning в продакшне\n",
    "\n",
    "Поговорим, от том, как выводить модели в продакшн. Вы уже знакомы с понятием \"жизненный цикл ML проекта\" - сегодня мы увидим, как этот цикл выглядит в реальной жизни и попробуем вывести в продакшн модель классификации с помощью технологии виртуализации Docker (можно и без docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом уроке мы поговорим о том, как обосновать перед бизнесом необходимость внедрения новой ML-системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оффлайн эксперимент. Proof concept\n",
    "\n",
    "В рамках курса вы\n",
    "* узнали про огромное количество моделей: классификация, регрессия\n",
    "* научились оценивать качество моделей \n",
    "* можете готовить данные для алгоритмов, включая генерацию фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, бизнесу не интересны задачи классификации или регрессии - бизнесу интересно зарабатывать деньги. Чтобы заработать деньги с помощью ML нужно найти конкретную бизнес-проблему, поиском проблем в бизнесе должен заниматься владелец бизнеса (в методологии Agile его зовут Product Owner) и понять, как эту бизнес-проблему можно решить. После такого  начального этапа выявления проблемы бизнес-хотелка отдаётся ML-специалисту, который должен создать инженерное решение для проблемы и интергрировать его в продакшн - после выкатывания прототипа \"в прод\" бизнес начинает зарабатывать миллионы и все счастливы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже я приведу полный путь от бизнес-идеи до прототипа - такой путь проходит любой проект ML, а называют такой пайплайн Proof of concect:\n",
    "\n",
    "1. Перейти от общих слов продукт оунера к конкретным бизнес-требованиям. Желательно, чтобы DS проводил её сам (возможно привлечь бизнес-аналитика).\n",
    "1. Описать дизайн (схему) эксперимента. Нужно понять, как повлиять на бизнес-метрики из первого пункта. На этом этапе нужно понять, какая информация доступна на входе, что ожидается на выходе и к какой задаче ML это можно свести  какие метрики покажут успешность задачи\n",
    "1. Разобраться с данными: где храняться достаточно ли их для проверки гипотезы. Неплохо бы сразу осознать, будут ли данные в продакшене отличаться от того, что доступно в трейне.\n",
    "1. Наинженерить фич и построить модель\n",
    "1. Оценить качество модели, посчитать технические и бизнесовые метрики (см. третий урок)\n",
    "1. Оценить ROI (Return on Investment) — ради этого всё и затевается.\n",
    "\n",
    "Фишка этих шагов в том, что ошибка на любом шаге сильно ухудшает весь проект - например, плохая постановка бизнес-требований приведёт к провальному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт ROI - самый важный, финальный этап. Без расчёта эффективности бизнес-заказчик не даст вам добра на выкатывание в продакшн. \n",
    "\n",
    "ROI  — это показатель доходности проекта, равный отношению доходов к затраченным инвестициям. ROI < 100% означает, что проект не окупится.\n",
    "\n",
    "`ROI` = (`LTP`)/(`CL` + `LTL`)\n",
    "\n",
    "1. LTP(Lifetime Profit)  - сколько доходов принесёт проект, пока его не свернут. Вычисляется как *операционные доходы* $\\times$ *срок жизни*\n",
    "1. CL (Capital Loss) - затраты на старт проекта\n",
    "1. LTL(Lifetime Loss)  - сколько расходов принесёт проект, пока его не свернут. Вычисляется как *операционные расходы проекта* $\\times$ *срок жизни проекта*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В капитальные затраты входит закупка железа и лицензий, разработку системы и ее внедрение. Операционные расходы - это то, что тратится на поддержание сервиса: зарплата программистов, devops-инженеров, аренда серверов.\n",
    "\n",
    "Из-за \"мгновенных\" капитальных расходов на старте проекта ROI будет зависеть от времени, на котором мы оцениваем доходность. Обычно для расчета ROI используется или год - нужно понять, окупится проект за год или нет.\n",
    "\n",
    "\n",
    "На далеком горизонте планирования можно окупить любую систему, поэтому важно понять величину *Lifetime* - сколко проработает система "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, что такое Proof of concept: какие действия нужно произвести чтобы понять, что модель будет полезна и принесёт выгоду. В следующем уроке мы поговорим о метриках сервиса - как понять, что модель действительно работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики моделей ML\n",
    "\n",
    "Метрики ML-сервисов (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* технические метрики сервиса\n",
    "* продуктовые (бизнес) метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оффлайн метрики\n",
    "\n",
    "Оффлайн-метрики показывают, насколько хорошо алгоритм \"выучил\" исторические данные. С этими метриками вы сталкивались в течение всего курса:\n",
    "\n",
    "* RMSE\n",
    "* MAE\n",
    "* precision\n",
    "* recall\n",
    "* accuracy\n",
    "* MAP\n",
    "* $\\ldots$\n",
    "\n",
    "Эти метрики не могут сказать, что модель будет достаточно хороша для бизнеса, но такая модель, как минимум, будет \"не совсем плоха\" чтобы отказываться от её выкатывания в прод. То есть выкатывают модель с хорошими оффлайн метриками и надеются, что она улучшит онлайн-метрики (см. дальше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальной жизни обучение модели запускается регулярно, поэтому оффлайн-метрики нуждаются в мониторинге.\n",
    "\n",
    "Пример из боевой системы обучения моделей: если ROC-AUC падает ниже 0.8, то модель в продакшн не выкатывается, а разработчику приходит уведомление в slack: дружище, с твоей моделью что-то не так, посмотри что случилось:\n",
    "\n",
    "<pre>\n",
    "12:11:52,344 | INFO     | hydramatrices_data.py    :65   | Данные из HDFS загружены\n",
    "12:12:10,651 | INFO     | learn2rank_model.py      :168  | Разбили данные на train и test\n",
    "12:13:15,113 | INFO     | learn2rank_model.py      :248  | Кол-во объектов в train 1643676\n",
    "12:14:24,329 | INFO     | learn2rank_model.py      :265  | Новая модель Learning to Rank c2c готова\n",
    "12:14:49,295 | INFO     | learn2rank_model.py      :268  | Train Area under ROC = 0.8517\n",
    "12:15:11,057 | INFO     | learn2rank_model.py      :272  | Test Area under ROC = 0.8516\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Технические метрики\n",
    "\n",
    "Технические метрики сервиса - это некоторые показатели \"здоровья\", железа, которые никак не связаны с логикой\n",
    "\n",
    "* RPS (response per second) - сколько запросов в секунду прилетает на сервис\n",
    "* response time - время ответа серсиса\n",
    "* CPU idle - \"бездействие системы\", чем больше тем лучше. Если падает idle - значит, сильно загружен процессор\n",
    "* available memory - сколько памяти доступно на серверах\n",
    "* 500 errors - количество 500-х ошибок на сервисе\n",
    "\n",
    "Дэшборды с техническими метриками могут выглядеть как-то так:\n",
    "\n",
    "![tech_metrics](img/tech_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сбора и визуализации технических метрик используются следующие инструменты, которые должен знать каждый ML специалист:\n",
    "\n",
    "* statsd - хранение метрик\n",
    "* Grafana - визуализиция графиков\n",
    "* Zabbix - визуализация и отправка уведомлений (например, в slack)\n",
    "* Sentry - для анализа 500-х ошибок\n",
    "* Kibana - логи сервиса\n",
    "\n",
    "Прежде чем катить модель в прод нужно ознакомиться с каждым из этих инструментов и интегрировать с ними свою модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продуктовые метрики\n",
    "\n",
    "Продуктовые метрики это то, что в первую очередь интересует бизнес. Когда выкатываете новую модель - она должна делать бизнесу лучше, а делать ML ради ML точно не стоит\n",
    "\n",
    "Какие метрики можно улучшить с помощью ML\n",
    "\n",
    "* средний чек\n",
    "* retention - возвращаемость клиентов на сервис\n",
    "* churn - отток клиентов с сервиса\n",
    "* bounce - % пользователей, которые зашли на сервис, но ничего не сделали  (показатель отказов)\n",
    "* конверсия в покупку\n",
    "\n",
    "Проверять, что ваша модель улучшает метрики следует с помощью АБ-теста\n",
    "\n",
    "![ab_testing](img/ab_testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, как следить за моделями в продакшн. Вы познакомились с понятием \"технические метрики сервиса\" и теперь знаете, как сделать из \"чёрного ящика\" вашей модели прозрачный и управляемый сервис \n",
    "\n",
    "В следующем уроке мы перейдём к самому интересному - поговорим, как разворачивать модели на боевых серверах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деплой модели: Docker\n",
    "\n",
    "Этапы разработки прод-сервиса:\n",
    "* разведочный анализ данных\n",
    "* прототип модели в Jupyter\n",
    "* продакшн-сервис\n",
    "\n",
    "Как же перейти от любимого Jupyter ноутбука к продакшин сервису? Современные архитектуры web-проектов предполагают т.н. микросервисную архитектуру, когда для решения конкретной бизнес задачи поднимается маленький веб-сервис, который умеет принимать http-запросы и делать predict, возвращая предсказания в виде json-объекта.\n",
    "\n",
    "JSON - это стадартный формат для общения микросервисов друг с другом, о нём говорили в самом начале курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как упаковать модель в микросервис? Для этого питоновский код нужно обернуть в http-сервер, который будет \"сёрвить\" (обслуживать) http-запросы. Вариантов http-сервера очень много\n",
    "\n",
    "* [Flask](https://palletsprojects.com/p/flask/)\n",
    "* [aiohttp](https://aiohttp.readthedocs.io/en/stable/)\n",
    "* [http.server](https://docs.python.org/3/library/http.server.html)\n",
    "\n",
    "Такой сервис обычно имеет url, на который можно отправлять запросы в заранее определённом формате, например `https://you.service/classify?uid=999` и возвращать ответ в JSON `{'uid': 999, 'class': 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чём тут Docker? Докер - это система виртуализации, которая позволяет унифицировать среду разработки и среду выполнения приложения: вы пишете код, который исполняется в виртуальной машине, тестируете его - а потом на боевые сервера отправляется та же самая виртуальная машина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что вам не нужно волноваться о том, как будет жить питоновский код в продакшне - потому что будет исполняться в той же среде, в которой вы его разрабатывали (и тестировали). Докер является де-факто стандартом в мире современных архитектур для деплоя (т.е. вывода в продакшн-среду) моделей ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой докер-контейнер\n",
    "\n",
    "Вы уже пользовались докером для разворачивания Postgres базы данных, но не писали своих докерфайлов. Давайте исправим этот факт и напишем простой докер-сервис! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм упаковки сервиса в докер следующий\n",
    "\n",
    "1. Выбрать базовый образ. Я выбрал образ, в который включены такие библиотеки как sklearn, numpy и pandas https://hub.docker.com/r/morpheo/sklearn-base/\n",
    "1. Чтобы докер делал что-то полезное, нужно запустить внутри него программу. Программы внутри контейнера принято запускать через файл `docker-entrypoint.sh`. Для примера я создал файл [simple-entrypoint.sh](docker_example/simple-entrypoint.sh), внутри которого всего одна инструкция `echo \"Hello, MAI!\"`\n",
    "1. Чтобы собрать контейнер, нужно описать его структуру в Dockerfile. Загляните в файл [Dockerfile_simple](docker_example/Dockerfile), где описана структура нашего контейнера\n",
    "\n",
    "<pre>\n",
    "FROM morpheo/sklearn-base\n",
    "\n",
    "COPY simple_entrypoint.sh /usr/local/bin/docker-entrypoint.sh\n",
    "RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
    "\n",
    "ENTRYPOINT [\"docker-entrypoint.sh\"]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находясь в директории `docker_example` надо запустить сборку контейнера командой\n",
    "```shell\n",
    "docker build . -f Dockerfile_simple -t mai:simple\n",
    "```\n",
    "\n",
    "После окончания процесса сборки запустить контейнер с помощью инструкции `docker run`:\n",
    "```shell\n",
    "docker run -it --rm  mai:simple\n",
    "```\n",
    "\n",
    "В результате должны увидеть в консоли `Hello, MAI!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы создали простой контейнер (для понимания), который только и умеет что выводить на печать простую фразу. В следующем уроке мы упакуем в докер пайплайн для тренировки и развёртывания модели машинного обучения в виде http-сервиса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упаковка модели в Docker\n",
    "\n",
    "Перед тем, как погружаться в мир докера, создадии пайплайн обучения на python.\n",
    "\n",
    "Начнём с загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_diff</th>\n",
       "      <th>sms_diff</th>\n",
       "      <th>traffic_diff</th>\n",
       "      <th>customes_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.666421</td>\n",
       "      <td>0.444911</td>\n",
       "      <td>-0.273538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.889273</td>\n",
       "      <td>-0.537896</td>\n",
       "      <td>-1.959469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.841503</td>\n",
       "      <td>0.846665</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call_diff  sms_diff  traffic_diff  customes_class\n",
       "0  -0.666421  0.444911     -0.273538             0.0\n",
       "1  -0.889273 -0.537896     -1.959469             2.0\n",
       "2  -0.841503  0.846665      0.727606             0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_source = pd.read_csv('data/client_segmentation.csv')\n",
    "X = df_source[['call_diff','sms_diff','traffic_diff']].values\n",
    "y = df_source.customes_class.values\n",
    "\n",
    "df_source.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это датасет, в котором три фичи `call_diff`, `sms_diff` и `traffic_diff` которые отражают относительное изменение в объёме звонков, смс и интернет-трафика соответственно по абонентам в базе телеком-оператора и несколько классов клиентов:\n",
    "\n",
    "* класс `0` - пользователь платит много\n",
    "* класс `1` - пользователь платит мало\n",
    "* класс `2` - пользователь ушёл в отток (не платит ничего)\n",
    "\n",
    "От нас требуется обучить модель классификации на три класса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для визуализации данных выполним понижение размерности с помощью t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "x_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "colors = ['bo', 'gx', 'ro']; num_labels = len(colors)\n",
    "# И нарисуем получившиеся точки в нашем новом пространстве\n",
    "for name, label, color in [('class_%d' % i, i, colors[i]) for i in range(num_labels)]:\n",
    "    plt.plot(x_tsne[y == label, 0], x_tsne[y == label, 1], color, label=\"class %d\" % label)\n",
    "plt.legend(loc=0); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бизнесу требуется построить классификатор клиентов - давате обучим простенький классификатор, основанный на решающем дереве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У объекта под номером 4 класс 2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# выбираем рандомный объект\n",
    "\n",
    "num_objects = X.shape[0]\n",
    "random_id = np.random.randint(num_objects)\n",
    "\n",
    "# преобразуем фичи, чтобы подошли на вход модели и делаем предсказания\n",
    "test_object = X[random_id,:].reshape(1, -1)\n",
    "pred = clf.predict(test_object)\n",
    "print(f\"У объекта под номером {random_id} класс {pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гототово, у нас есть модель, которая что-то обучает и что-то предсказывает. Можем сериализовать её для дальнейшего использования c помощью `pickle`. А теперь попробуем обернуть в докер наш пайплан обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый контейнер для сервиса я взял отсюда: https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/ . Он включает python 3.5 и библиотеки numpy и sklearn - больше нам для обучения модели ниего не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск сборки\n",
    "```shell\n",
    " docker build . -f Dockerfile -t mai:advanced\n",
    "```\n",
    "Запуск обучения модели - см. файл `train.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data mai:advanced train_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся полезная информация отправляется в файл с логами\n",
    "```shell\n",
    "tail -n1 data/service.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример логов модели\n",
    "```shell\n",
    "2020-04-24 06:55:54,070 | INFO     | service.py               :70   | Загружаем обученную модель\n",
    "2020-04-24 06:55:54,071 | INFO     | service.py               :73   | Модель загружена: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=42, splitter='best')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск микросервиса - см. в файле `service.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data -p 5000:5000 -d mai:advanced start_service\n",
    "```\n",
    "\n",
    "Увидеть запущенный контейнер можно через Docker ps\n",
    "```shell\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Результат команды\n",
    "```shell\n",
    "CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
    "c9ba7303712c        mai:advanced   \"docker-entrypoint.s…\"   14 hours ago        Up 14 hours         0.0.0.0:5000->5000/tcp   infallible_easley\n",
    "```\n",
    "\n",
    "Чтобы проверить, что сервис \"жив\" и способен принимать запросы откройте в браузере спициальную страничку `http://0.0.0.0:5000/ping/` - это т.н. *healh check* нашего сервиса. В браузере должно появится\n",
    "```json\n",
    "{\"message\": \"pong\"}\n",
    "```\n",
    "\n",
    "Хороший туториал по [упаковке моделей в контейнеры](https://towardsdatascience.com/deploying-machine-learning-models-with-docker-5d22a4dacb5). Там можно почитать, как скейлить нагрузку помощью nginx+gunikorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем датасете три фичи - нам нужно передать их в наш микросервис. Передавать фичи можно через GET-запросы, например, так:\n",
    "```url\n",
    "http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
    "```\n",
    "\n",
    "Дальше нам нужно перехватить их на стороне сервиса, обработать фичи, загрузив в классификатор и выдать ответ:\n",
    "```json\n",
    "{\"x1\": 1.0, \"x2\": -2.2, \"x3\": 1.05, \"predicted_class\": 0}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После окончания работ контейнер можно остановить\n",
    "```shell\n",
    "docker stop c9ba7303712c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы упаковали модель в докер и можем использовать модель как микросервис - отправлять запросы и получать предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим все наши знания о микросервисах в одной картинке\n",
    "\n",
    "* у микросервиса должен быть определён формат ответа в виде JSON схемы\n",
    "* Consul - это сервис, который автоматически дёргает *health check* и рестартует контейнер, если он перестал отвечать\n",
    "* блок `logs` - это Elastic+Logstash+Kibana, связка используется для хранения логов\n",
    "* технические метрики отправляются в хранилище Prometheus и визуализируются  в Grafana. Нотификации в случае нештатных ситуаций отправляются в Slack\n",
    "* инциденты в виде 500-х ошибок отправляются в Sentry для дальнейшего анализа\n",
    "\n",
    "![microservice.png](img/microservice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: применяем t-sne\n",
    "\n",
    "Модифицируйте файл `train.py` - добавьте в пайплайн обучения модели сжатие размерности до `n_components=2` с помощью t-sne и обучите модель **в докере** на \"сжатых\" данных. Сохраните полученный объект `tsne_tansformer.pkl`, который умеет выполнять это задание.\n",
    "\n",
    "Решением домашки считается модифицированный файл *train.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: трансформация входных фичей на лету\n",
    "\n",
    "Модифицируйте файл `service.py`: добавьте загрузку объекта для трансформации `tsne_tansformer.pkl` и применяйте её **в докере** для трансформации набора входных фич в сжатые:\n",
    "<pre>\n",
    "[x1, x2, x3] -> [x1_tsne, x2_tsne]\n",
    "</pre>\n",
    "\n",
    "Соответственно, predict надо выполнять на *сжатых* фичах\n",
    "\n",
    "\n",
    "Решением домашки считается модифицированный файл *service.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Используем Flask\n",
    "\n",
    "Перепишите сервис на использование Flask. Вы можете взять готовый базовый образ с Flask, либо добавить установку в тот контейнер, который есть - это нужно сделать в Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML в проде: рекомендательные системы\n",
    "\n",
    "Рекомендательные системы - это обобщённое название для сервисов, которые в ответ на запрос формируют из огромной коллекции доступных сущностей (мы будем называть их \"документами\", англ. item но в реальной жизни это фильмы в онлайн-кинотеатре или товары в интернет-магазине, а саму такую коллекцию документов для краткости будем называть каталогом) некоторый шорт-лист, который будет наиболее подходящим для данного запроса (такие документы называются \"релевантными\"). Рекомендательные системы используют для решения своих задач другие алгоритмы ML.\n",
    "О том, как на основе уже изученных ML-алгоритмов научиться решать задачу поиска релевантных объектов мы поговорим в этом  уроке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы: цели и задачи\n",
    "\n",
    "Основная задача рекомендательной системы - нарезать шорт-лист из каталога, который будет максимально подходить к контексту, в котором запрашиваются рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под \"контекстом\" мы понимаем различные параметры мира, который окружает рекомендательную систему:\n",
    "\n",
    "* с какими документами из каталога уже взаимодействовал пользователь\n",
    "* какова \"сила\" взаимодействия - лайк или дизлайк? Если оценка - то какая? Если просмотр фильма - то как долго смотрел?\n",
    "* в какой стране находится пользователь - в Казахстане смотрят фильм \"Рэкетир\" а в России \"Бумер\".\n",
    "* утро или вечер в момент посмотрения рекомендаций\n",
    "* что по соцдему - какого пола и возраста пользователь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача рекомендаций представляет собой задачу *ранжирования* - мы пытаемся расставить контент в таком порядке, чтобы в начале списка был самый релевантный контент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, например, как выглядит главная страница ivi - по сути, это персонализованная нарезка из доступного каталога контента\n",
    "\n",
    "![ivi_main](img/ivi_catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Различают два вида рекомендаций:\n",
    "\n",
    "* *content to user*  строятся на основе фидбэка, полученного от пользователя (например, лайкнутые фильмы)\n",
    "* *content to content* строятся на основе свойств контента найти максимально похожие на него элементы (например, блок \"С этим часто покупают\" на Ozon)\n",
    "\n",
    "Рекомендательная система решает задачу персонализации сервиса - это значит, что каждый пользователь  видит свой вариант сервиса - можно сказать, что у вас появляется столько вариантов наполнения страниц вашего сайта, сколько у вас пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендательные системы нужны в ситуации, когда пользователь не может сделать выбор из огромного количества возможных вариантов каталога (например, каталога интернет-магазина) и ему нужно как-то помочь, ограничив выбор узким кругом объектов, которые больше всего подходят к текущему контексту - такие объекты и называются *релевантными*. Избавив пользователя от необходимости просматривать огромное число неподходящих объектов, рекомендательная система позволяет быстрее сконвертировать пользовательскую сессию в \"целевое действие\" - просмотр фильма или покупку гаджета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два основных метода для поиска релелевантных объектов\n",
    "\n",
    "* collaborative filtering\n",
    "* content filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели *коллаборативной фильтрации* используют интуитивное предположение о том, что если у двух пользователей сильно пересекаются два множества контента (с которым они взаимодействовали) то у этих двух пользователей схожие вкусы - на основе этого можно делать рекомендации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть информация о пользователях `X, Y, Z` и фильмах `A, B, C, D, E`. В таблице символ \"+\" означает, что пользователь $i$ смотрел фильм $j$:\n",
    "\n",
    "| - | A | B | C | D | E |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| X  | +  | -  | +  | +  | -  |\n",
    "| Y  | -  | +  | -  | -  | +  |\n",
    "| Z  | +  | +  | -  | +  | -  |\n",
    "\n",
    "Как видно, пользователи `X, Z` очень похожи друг на друга, т.к. им обоим нравится фильмы \"А\" и \"D\".\n",
    "\n",
    "В то же время пользователь `Y` не похож на них, он смотрит другие фильмы. Из картинки видно, что если бы нам нужно было бы построить персональные рекомендации для пользователя `X`, то мы бы порекомендовали  ему фильм `B` - такой фильм смотрел пользователь Z и значит, этот фильм понравится пользователю X, потому что данные говорят о том, чт вкусы этих двух пользователей похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Content-based* фильтрация подбирает похожие элементы на основе свойств контента. Например, в случае фильма его свойства - это актёр, режиссёр, жанр, место действия и т.д. Например, если у нас естьфильм со Стэтхемом, то максимально похожим будет, скорее всего, другой фильм со Стэтхэмом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выделяют *гибридные* рекомендательные системы - в этом случае рекомендации из нескольких моделей (например, `content based` + `collaborative filterig`) используются для формирования итогового ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативные модели обучаются на триплетах (тройках) `(user, item, feedback)`, где для каждой пары `(user, item)` фидбэк может быть двух видов:\n",
    "\n",
    "* explicit (явный)\n",
    "* implicit (неявный)\n",
    "\n",
    "*Явный фидбэк* - это любое явное выражение пользователем своего отношения к контенту: лайк, оценка и т.д. *Неявный фидбэк* - это длительность просмотра фильма, количество заходов на карточку товара, время чтения статьи и т.д.: интуитивно понятно, что если пользователь смотрит фильм долго - то такой фильм, скорее всего, ему нравится, но явного сигнала (например, в виде лайка) мы не получаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача построения рекомендации решается с помощью классических алгоритмов машинного обучения:\n",
    "\n",
    "* метод ближайших соседей (knn)\n",
    "* матричная факторизация\n",
    "* логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендатель отдаёт отранжированный список объектов. На этот список обычно накладываются разнообразные бизнес-правила, позволяющие оптимизировать метрики, важные для бизнеса: например, искуственное повышение новинок в выдаче.\n",
    "\n",
    "Грамотно построенная рекомендательная система позволяет нарастить продуктовые метрики. Например, в онлайн-кинотеатре:\n",
    "\n",
    "* растёт конверсия в просмотр т.к. пользователь получает на главной странице самый подходящий контент\n",
    "* увеличивается длительности смотрения на пользователя, удачно рекомендованный сериал генерирует десятки часов смотрения\n",
    "* уменьшается отток с сервиса - пользователь за одну сессию может выбрать несколько фильмов, которые будет смотреть несколько заходов подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN рекомендации\n",
    "\n",
    "Мы попробуем построить простейшую модель коллаборативной фильтрации, пользуясь только информацией оп просмотрах контента в онлайн-кинотеатре ivi.\n",
    "\n",
    "Загрузим исходные данные - там примерно полмиллиона просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим дополнительную информацию о контенте: жанры, дату появления на сервисе, рейтинг кинопоиска и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "\n",
       "       genre  \n",
       "0  Для детей  \n",
       "1  Для детей  \n",
       "2  Для детей  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "\n",
    "content_description.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем разреженную матрицу user-item такую, что\n",
    "\n",
    "* количество строк матрицы совпадает с числом пользователей\n",
    "* количество столбцов матрицы совпадает с количеством контента\n",
    "* на пересечении столбца $i$ и строки $j$ стоит единица, если пользователь $i$ смотрел контент $j$, иначе - ноль\n",
    "\n",
    "Для начала перейдём от индекса контента и индекса пользователя к индексам в разреженной матрице - воспользуемся `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть колонки `user_index, item_index`, которые соответствуют номерам строки и столбца соответственно в матрице user-item. Передадим полученные колонки в конструктор `csr_matrix`, чтобы получить разреженную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на валидацию и контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки 1600 пользователей, размер валидационной выборки 400 пользователей\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"Размер обучающей выборки %d пользователей, размер валидационной выборки %d пользователей\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в наше матрице 2000 пользователей и 27012 единиц контента, у матрицы высокая разреженность - менее 1% ненулевых элементов, остальное заполнено нулями.\n",
    "\n",
    "Чтобы строить рекомендации по колаборативной модели, нам нужен быстрый способ поиска пользователей, у которых схожая история просмотров- наше предположение в том, что похожие пользователи имеют похожую историю просмотров. Для поиска схожих пользователей воспользуемся поиском ближайших соседей по нашей матрице `user-item`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "model_knn.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейший класс, который умеет искать похожих по истории смотрения пользователей и выдавать рекомендации. Рекомендации - это контент, который смотрели ближашие соседи пользователя, а сам пользователь этот контент не видел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeFilteringKNNRecommender:\n",
    "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
    "        self.knn_model = knn_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.top_recs = 50\n",
    "    \n",
    "    def make_recs(self, user_history: csr_matrix, top_recs: int):\n",
    "        neighbors = model_knn.kneighbors(\n",
    "            random_user_history,\n",
    "            self.num_neighbors,\n",
    "            return_distance=False\n",
    "        )[0]\n",
    "        full_recs = user_item[neighbors,:].max(axis=0)\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        user_history_ids = user_history.nonzero()[1]\n",
    "        # последовательность id того контента, который смотрели ближайшие соседи\n",
    "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
    "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
    "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
    "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
    "        \n",
    "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
    "\n",
    "\n",
    "# объект рекомендателя\n",
    "recommender = ColaborativeFilteringKNNRecommender(\n",
    "    knn_model=model_knn,\n",
    "    user_item_matrix=user_item,\n",
    "    num_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем рекомендатель для случайного пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число успешных рекомендаций 0 из 10\n",
      "user_index 1778, history: [17078 17079]\n",
      "recommendations: [ 1640  1988  1989  1990  1991  1992  6615  6635 12894 13899]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = recommender.make_recs(random_user_history, top_recs=10)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод `similar_items` для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили простейшую рекомендательную систему, основанную на колаборативной фильтрации и поиске ближайших соседей. В следующем уроке мы узнаем, как перейти от рекомендаций основанных на knn к более сложной концепции эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Эмбеддинги пользователей и контента (скрытые факторы)\n",
    "\n",
    "Рекомендации, которые строятся на основе KNN, имеют следующий недостаток: фактическим мы запоминаем матрицу `user-item` на этапе тренировки модели - такие модели называются *memory-based*. Это привобдит к большому расходу памяти на этапе получения предсказаний, т.к. по каждому пользователю мы вынуждены хранить разреженный вектор большой размерности. При росте количества пользователей модель начинает критически быстро расти по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход заключается в применении матричного разложения - когда мы пытаемся приблизить нашу большую разреженную матрицу user-item размерности $m\\times n$ двумя плотными матрицами, которые называются матрицей латентных (скрытых) факторов пользователей размерности $m\\times f$ и матрицей скрытых факторов контента размерности $n \\times f$. О таких методах мы уже говорили в уроке по теме \"Снижение размерности\" курса \"Машинное обучение. Начальный уровень\". Такой подход, при котором мы запоминаем не матрицу user-item, а только некий полезный сигнал из этой матрицы, называется *model-based*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фокус в том, что $m,n$ - это числа порядка десятков тысяч, а $f$ имеет небольшую размерность (обычно 30-50). Кажому пользователю и каждой единице понтента при таком подходе ставится в соответствие вектор размерности $f$, а произведение вектора пользователя $p_u$ на вектор контента $q_i$ даёт единственное число $r_{ui}$ - меру \"релевантности\", насколько данный контент понравится данному пользователю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svd_decomp](img/svd_decomp.png)\n",
    "\n",
    "$$\n",
    "r_{ui} = q_i^Tp_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для матричного разложения используются различные алгоритмы:\n",
    "\n",
    "* Singular Vector Decomposition (SVD)\n",
    "* Alternative Least Squares (ALS)\n",
    "* Bayesian personalized ranking (BPR)\n",
    "\n",
    "При решении реальных задач советую начать с BPR - он даёт отличные результаты, но у него есть и недостаток - вычислительная сложность, которая увеличивает время обучения.\n",
    "\n",
    "Выбирая между SVD и ALS я рекомендую выбирать ALS, т.к. он более новый и более быстрый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы продемонстрируем работу рекомендательной системы на примере SVD-разложения - для этотго даже не нужно устанавливать дополнительные пакеты, нужная функция есть прямо в пакете `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 27012) (2000, 50) (2000, 50)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "latent_factors_num = 50\n",
    "# раскладываем Useк-Item матрицу\n",
    "user_factors, scale, item_factors = svds(\n",
    "    user_item.asfptype(),\n",
    "    k=latent_factors_num,\n",
    "    return_singular_vectors=True\n",
    ")\n",
    "scale = np.diag(np.sqrt(scale))\n",
    "# эмбеддинги пользователей\n",
    "user_factors = np.dot(user_factors, scale).astype(np.float32)\n",
    "# эмбеддинги контента\n",
    "item_factors = np.dot(scale, item_factors).astype(np.float32)\n",
    "\n",
    "print(user_item.shape, user_factors.shape, user_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем класс, который будет формировать рекомендации на основе матриц `user_factors` и `item_factors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1656, 13341, 24689, 24688, 17085, 24686, 17080, 17088, 24687,\n",
       "       21915, 17086, 24704, 21913, 24691, 24698, 21912, 21910, 21919,\n",
       "       17091, 21907])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColaborativeFilteringFactorizationRecommender:\n",
    "    def __init__(self, user_factors, item_factors, user_item_matrix):\n",
    "        self.user_factors = user_factors\n",
    "        self.item_factors = item_factors\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "    \n",
    "    def make_recs(self, user_index):\n",
    "        user_factors = self.user_factors[user_index,:]\n",
    "        user_history_ids = self.user_item_matrix.getrow(user_index).nonzero()[1]\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        personal_scores = user_factors.reshape(1, -1).dot(self.item_factors).flatten()\n",
    "        personal_recs = np.argsort(-personal_scores)[:20]\n",
    "        \n",
    "        return np.array([i for i in personal_recs if i not in user_history_ids])\n",
    "\n",
    "factorization_recommender = ColaborativeFilteringFactorizationRecommender(\n",
    "    user_factors=user_factors,\n",
    "    item_factors=item_factors,\n",
    "    user_item_matrix=user_item\n",
    ")\n",
    "\n",
    "factorization_recommender.make_recs(random_user_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативная модель на основе скрытых факторов пользователя/контента позволяет быстро получить список релевантного контента для каждого пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этому уроке мы поговорили о том, как перейти от memory-based рекомендателям к model-based. В следующем уроке обсудим, а как измеряют эффективность рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики рекомендательных систем\n",
    "\n",
    "Мы научились делать персональные рекомендации единиц каталога. В этом уроке поговорим о том, как отделить \"хорошие\" модели от \"плохих\"\n",
    "\n",
    "Метрики рекомендательной системы (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* продуктовые (бизнес) метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продуктовые метрики - это то, как пользователи реагируют на рекомендации. К пользовательским метрикам можно отнести:\n",
    "\n",
    "* конверсию (в просмотр, в покупку и т.д.) - чем выше конверсия, тем лучше модель \n",
    "* длительность нахождения на сервисе (чем дольше, тем лучше)\n",
    "* поизицию, до которой были просмотрены рекомендации - чем меньше позиций пролистали, тем лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Продуктовые метрики** (иногда их называют онлайн-метриками) можно измерить, только проведя АБ-тест, эксперимент на реальных пользователях сервиса. Механика проведения эксперимента следующая мы делим пользователей на две группы: группа А видит старый вариант алгоритма, группа Б - новый вариант. После окончания теста сравнивается значение в тестовой группе и контрольной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оффлайн-метрики** рекомендательных систем позволяют проверить, насколько качественные прогнозы выполняет модель, пользуясь историческими данными.\n",
    "\n",
    "Для этой задачи можно приспособить известную Вам метрику **RMSE**, которая определяет, насколько точно мы приблизили матрицу *user-item*\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(a_{ij}-\\hat{a}_{ij})^2}\n",
    "$$\n",
    "\n",
    "Где $a_{ij}$ - истинное значение фидбека пользователя $i$ для контента $j$, а $\\hat{a}_{ij}$ - значение фидбэка, которое предсказала наша модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это неплохая метрика, например, для задачи регрессии, но для рекомендаций она немного странная - в принципе, нам не важно, насколько хорошо предсказываются оценки 2,3,4 - мы хотим уверенном предсказывать высокие оценки: 8,9,10.\n",
    "\n",
    "Другой пример метрик - это метрики из задач классификации (precision + reccall).\n",
    "\n",
    "Допустим, у нас есть список рекомендаций из $n=5$ элементов и список фактических просмотров из $k=3$ элементов. В красную рамку обведены те рекомендации, которые были фактически просмотрены - количество таких фильмов $m = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eval](img/eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**  показывает отношение товаров, купленных из рекомендаций к общему числу фактических просмотров\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{m}{k} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "**Precision**  показывает, насколько много из рекомендованного нами попало в итоге в просмотренное\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{m}{n} = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "У precision заметен один недостаток - игнорируется порядок, в котором пользователя заинтересовали рекомендованные объекты. Эту задачу решает метрика *average precision at K*. В числителе дисконтируем каждую \"единичку\", на ту позицию, где она стоит:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{ap} = \\frac{1}{5}\\left( 0 + \\frac{1}{2} + \\frac{1}{3}\\right) = \\frac{1}{5}\\cdot \\frac{5}{6} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "при такой модификации мы заставляем модель не просто угадывать релевантные объекты, но и \"поднимать\" их выше к началу списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме перечисленных выше метрик, которые измеряют точность \"угадывания\", можно мерять и другие показатели\n",
    "\n",
    "* diversity (разннообразие выдачи) - как сильно в выдаче представлены разные жанры, авторы и т.д.\n",
    "* coverage (покарытие каталога) - какая часть каталога покрывается рекомендациями (следует избегать случаев, когда всем пользователям рекомендуюется одно и то же подмножество)\n",
    "* serendipity (индивидуальность) -  берем разницу между вероятностью рекомендации айтема юзеру и всем юзерам (т.е. насколько рекомендация индивидуальна) и суммируем по всем релевантным рекомендованым айтемам. Позволяет определить, насколько выдача \"заточена\" под польователя\n",
    "* novelty (новизна) - как часто попадают в выдачу новые (холодные) элементы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание на метрики\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "# --- ВАШ КОД ТУТ ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке познакомились с метриками. Теперь вы можете отличать хорошие модели рекомендаций от плохих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы мознакомились с темой рекомендательных систем. Это область знаний, которую \"просто выучить, сложно понять\" - потому что с помощью простых алгоритмов ML можно сильно увеличить эффективность вашего бизнеса, но правильное применение этих методов к задаче построения рекомендательной системы - особое искусство, требующее хорошего понимания бизнес-области и знания специфических метрик систем ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
