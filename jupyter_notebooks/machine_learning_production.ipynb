{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning в продакшне\n",
    "\n",
    "Поговорим, от том, как выводить модели в продакшн. Вы уже знакомы с понятием \"жизненный цикл ML проекта\" - сегодня мы увидим, как этот цикл выглядит в реальной жизни и попробуем вывести в продакшн модель классификации с помощью технологии виртуализации Docker (можно и без docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом уроке мы поговорим о том, как обосновать перед бизнесом необходимость внедрения новой ML-системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оффлайн эксперимент. Proof concept\n",
    "\n",
    "В рамках курса вы\n",
    "* узнали про огромное количество моделей: классификация, регрессия\n",
    "* научились оценивать качество моделей \n",
    "* можете готовить данные для алгоритмов, включая генерацию фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, бизнесу не интересны задачи классификации или регрессии - бизнесу интересно зарабатывать деньги. Чтобы заработать деньги с помощью ML нужно найти конкретную бизнес-проблему, поиском проблем в бизнесе должен заниматься владелец бизнеса (в методологии Agile его зовут Product Owner) и понять, как эту бизнес-проблему можно решить. После такого  начального этапа выявления проблемы бизнес-хотелка отдаётся ML-специалисту, который должен создать инженерное решение для проблемы и интергрировать его в продакшн - после выкатывания прототипа \"в прод\" бизнес начинает зарабатывать миллионы и все счастливы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже я приведу полный путь от бизнес-идеи до прототипа - такой путь проходит любой проект ML, а называют такой пайплайн Proof of concect:\n",
    "\n",
    "1. Перейти от общих слов продукт оунера к конкретным бизнес-требованиям. Желательно, чтобы DS проводил её сам (возможно привлечь бизнес-аналитика).\n",
    "1. Описать дизайн (схему) эксперимента. Нужно понять, как повлиять на бизнес-метрики из первого пункта. На этом этапе нужно понять, какая информация доступна на входе, что ожидается на выходе и к какой задаче ML это можно свести  какие метрики покажут успешность задачи\n",
    "1. Разобраться с данными: где храняться достаточно ли их для проверки гипотезы. Неплохо бы сразу осознать, будут ли данные в продакшене отличаться от того, что доступно в трейне.\n",
    "1. Наинженерить фич и построить модель\n",
    "1. Оценить качество модели, посчитать технические и бизнесовые метрики (см. третий урок)\n",
    "1. Оценить ROI (Return on Investment) — ради этого всё и затевается.\n",
    "\n",
    "Фишка этих шагов в том, что ошибка на любом шаге сильно ухудшает весь проект - например, плохая постановка бизнес-требований приведёт к провальному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт ROI - самый важный, финальный этап. Без расчёта эффективности бизнес-заказчик не даст вам добра на выкатывание в продакшн. \n",
    "\n",
    "ROI  — это показатель доходности проекта, равный отношению доходов к затраченным инвестициям. ROI < 100% означает, что проект не окупится.\n",
    "\n",
    "`ROI` = (`LTP`)/(`CL` + `LTL`)\n",
    "\n",
    "1. LTP(Lifetime Profit)  - сколько доходов принесёт проект, пока его не свернут. Вычисляется как *операционные доходы* $\\times$ *срок жизни*\n",
    "1. CL (Capital Loss) - затраты на старт проекта\n",
    "1. LTL(Lifetime Loss)  - сколько расходов принесёт проект, пока его не свернут. Вычисляется как *операционные расходы проекта* $\\times$ *срок жизни проекта*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В капитальные затраты входит закупка железа и лицензий, разработку системы и ее внедрение. Операционные расходы - это то, что тратится на поддержание сервиса: зарплата программистов, devops-инженеров, аренда серверов.\n",
    "\n",
    "Из-за \"мгновенных\" капитальных расходов на старте проекта ROI будет зависеть от времени, на котором мы оцениваем доходность. Обычно для расчета ROI используется или год - нужно понять, окупится проект за год или нет.\n",
    "\n",
    "\n",
    "На далеком горизонте планирования можно окупить любую систему, поэтому важно понять величину *Lifetime* - сколко проработает система "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, что такое Proof of concept: какие действия нужно произвести чтобы понять, что модель будет полезна и принесёт выгоду. В следующем уроке мы поговорим о метриках сервиса - как понять, что модель действительно работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики моделей ML\n",
    "\n",
    "Метрики ML-сервисов (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* технические метрики сервиса\n",
    "* продуктовые (бизнес) метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оффлайн метрики\n",
    "\n",
    "Оффлайн-метрики показывают, насколько хорошо алгоритм \"выучил\" исторические данные. С этими метриками вы сталкивались в течение всего курса:\n",
    "\n",
    "* RMSE\n",
    "* MAE\n",
    "* precision\n",
    "* recall\n",
    "* accuracy\n",
    "* MAP\n",
    "* $\\ldots$\n",
    "\n",
    "Эти метрики не могут сказать, что модель будет достаточно хороша для бизнеса, но такая модель, как минимум, будет \"не совсем плоха\" чтобы отказываться от её выкатывания в прод. То есть выкатывают модель с хорошими оффлайн метриками и надеются, что она улучшит онлайн-метрики (см. дальше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальной жизни обучение модели запускается регулярно, поэтому оффлайн-метрики нуждаются в мониторинге.\n",
    "\n",
    "Пример из боевой системы обучения моделей: если ROC-AUC падает ниже 0.8, то модель в продакшн не выкатывается, а разработчику приходит уведомление в slack: дружище, с твоей моделью что-то не так, посмотри что случилось:\n",
    "\n",
    "<pre>\n",
    "12:11:52,344 | INFO     | hydramatrices_data.py    :65   | Данные из HDFS загружены\n",
    "12:12:10,651 | INFO     | learn2rank_model.py      :168  | Разбили данные на train и test\n",
    "12:13:15,113 | INFO     | learn2rank_model.py      :248  | Кол-во объектов в train 1643676\n",
    "12:14:24,329 | INFO     | learn2rank_model.py      :265  | Новая модель Learning to Rank c2c готова\n",
    "12:14:49,295 | INFO     | learn2rank_model.py      :268  | Train Area under ROC = 0.8517\n",
    "12:15:11,057 | INFO     | learn2rank_model.py      :272  | Test Area under ROC = 0.8516\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Технические метрики\n",
    "\n",
    "Технические метрики сервиса - это некоторые показатели \"здоровья\", железа, которые никак не связаны с логикой\n",
    "\n",
    "* RPS (response per second) - сколько запросов в секунду прилетает на сервис\n",
    "* response time - время ответа серсиса\n",
    "* CPU idle - \"бездействие системы\", чем больше тем лучше. Если падает idle - значит, сильно загружен процессор\n",
    "* available memory - сколько памяти доступно на серверах\n",
    "* 500 errors - количество 500-х ошибок на сервисе\n",
    "\n",
    "Дэшборды с техническими метриками могут выглядеть как-то так:\n",
    "\n",
    "![tech_metrics](img/tech_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сбора и визуализации технических метрик используются следующие инструменты, которые должен знать каждый ML специалист:\n",
    "\n",
    "* statsd - хранение метрик\n",
    "* Grafana - визуализиция графиков\n",
    "* Zabbix - визуализация и отправка уведомлений (например, в slack)\n",
    "* Sentry - для анализа 500-х ошибок\n",
    "* Kibana - логи сервиса\n",
    "\n",
    "Прежде чем катить модель в прод нужно ознакомиться с каждым из этих инструментов и интегрировать с ними свою модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продуктовые метрики\n",
    "\n",
    "Продуктовые метрики это то, что в первую очередь интересует бизнес. Когда выкатываете новую модель - она должна делать бизнесу лучше, а делать ML ради ML точно не стоит\n",
    "\n",
    "Какие метрики можно улучшить с помощью ML\n",
    "\n",
    "* средний чек\n",
    "* retention - возвращаемость клиентов на сервис\n",
    "* churn - отток клиентов с сервиса\n",
    "* bounce - % пользователей, которые зашли на сервис, но ничего не сделали  (показатель отказов)\n",
    "* конверсия в покупку\n",
    "\n",
    "Проверять, что ваша модель улучшает метрики следует с помощью АБ-теста\n",
    "\n",
    "![ab_testing](img/ab_testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, как следить за моделями в продакшн. Вы познакомились с понятием \"технические метрики сервиса\" и теперь знаете, как сделать из \"чёрного ящика\" вашей модели прозрачный и управляемый сервис \n",
    "\n",
    "В следующем уроке мы перейдём к самому интересному - поговорим, как разворачивать модели на боевых серверах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деплой модели: Docker\n",
    "\n",
    "Этапы разработки прод-сервиса:\n",
    "* разведочный анализ данных\n",
    "* прототип модели в Jupyter\n",
    "* продакшн-сервис\n",
    "\n",
    "Как же перейти от любимого Jupyter ноутбука к продакшин сервису? Современные архитектуры web-проектов предполагают т.н. микросервисную архитектуру, когда для решения конкретной бизнес задачи поднимается маленький веб-сервис, который умеет принимать http-запросы и делать predict, возвращая предсказания в виде json-объекта.\n",
    "\n",
    "JSON - это стадартный формат для общения микросервисов друг с другом, о нём говорили в самом начале курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как упаковать модель в микросервис? Для этого питоновский код нужно обернуть в http-сервер, который будет \"сёрвить\" (обслуживать) http-запросы. Вариантов http-сервера очень много\n",
    "\n",
    "* [Flask](https://palletsprojects.com/p/flask/)\n",
    "* [aiohttp](https://aiohttp.readthedocs.io/en/stable/)\n",
    "* [http.server](https://docs.python.org/3/library/http.server.html)\n",
    "\n",
    "Такой сервис обычно имеет url, на который можно отправлять запросы в заранее определённом формате, например `https://you.service/classify?uid=999` и возвращать ответ в JSON `{'uid': 999, 'class': 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чём тут Docker? Докер - это система виртуализации, которая позволяет унифицировать среду разработки и среду выполнения приложения: вы пишете код, который исполняется в виртуальной машине, тестируете его - а потом на боевые сервера отправляется та же самая виртуальная машина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что вам не нужно волноваться о том, как будет жить питоновский код в продакшне - потому что будет исполняться в той же среде, в которой вы его разрабатывали (и тестировали). Докер является де-факто стандартом в мире современных архитектур для деплоя (т.е. вывода в продакшн-среду) моделей ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой докер-контейнер\n",
    "\n",
    "Вы уже пользовались докером для разворачивания Postgres базы данных, но не писали своих докерфайлов. Давайте исправим этот факт и напишем простой докер-сервис! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм упаковки сервиса в докер следующий\n",
    "\n",
    "1. Выбрать базовый образ. Я выбрал образ, в который включены такие библиотеки как sklearn, numpy и pandas https://hub.docker.com/r/morpheo/sklearn-base/\n",
    "1. Чтобы докер делал что-то полезное, нужно запустить внутри него программу. Программы внутри контейнера принято запускать через файл `docker-entrypoint.sh`. Для примера я создал файл [simple-entrypoint.sh](docker_example/simple-entrypoint.sh), внутри которого всего одна инструкция `echo \"Hello, MAI!\"`\n",
    "1. Чтобы собрать контейнер, нужно описать его структуру в Dockerfile. Загляните в файл [Dockerfile_simple](docker_example/Dockerfile), где описана структура нашего контейнера\n",
    "\n",
    "<pre>\n",
    "FROM morpheo/sklearn-base\n",
    "\n",
    "COPY simple_entrypoint.sh /usr/local/bin/docker-entrypoint.sh\n",
    "RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
    "\n",
    "ENTRYPOINT [\"docker-entrypoint.sh\"]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находясь в директории docker_example надо запустить сборку контейнера командой\n",
    "<pre>\n",
    "docker build . -f Dockerfile_simple -t mai_simple:latest\n",
    "</pre>\n",
    "\n",
    "После окончания процесса сборки запустить контейнер с помощью инструкции `docker run`:\n",
    "<pre>\n",
    "docker run -it --rm  mai_simple:latest\n",
    "</pre>\n",
    "\n",
    "В результате должны увидеть в консоли `Hello, MAI!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы создали простой контейнер (для понимания), который только и умеет что выводить на печать простую фразу. В следующем уроке мы упакуем в докер пайплайн для тренировки и развёртывания модели машинного обучения в виде http-сервиса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упаковка модели в Docker\n",
    "\n",
    "Перед тем, как погружаться в мир докера, создадии пайплайн обучения на python.\n",
    "\n",
    "Начнём с загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_diff</th>\n",
       "      <th>sms_diff</th>\n",
       "      <th>traffic_diff</th>\n",
       "      <th>customes_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.666421</td>\n",
       "      <td>0.444911</td>\n",
       "      <td>-0.273538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.889273</td>\n",
       "      <td>-0.537896</td>\n",
       "      <td>-1.959469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.841503</td>\n",
       "      <td>0.846665</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call_diff  sms_diff  traffic_diff  customes_class\n",
       "0  -0.666421  0.444911     -0.273538             0.0\n",
       "1  -0.889273 -0.537896     -1.959469             2.0\n",
       "2  -0.841503  0.846665      0.727606             0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_source = pd.read_csv('data/client_segmentation.csv')\n",
    "X = df_source[['call_diff','sms_diff','traffic_diff']].values\n",
    "y = df_source.customes_class.values\n",
    "\n",
    "df_source.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это датасет, в котором три фичи `call_diff`, `sms_diff` и `traffic_diff` которые отражают относительное изменение в объёме звонков, смс и интернет-трафика соответственно по абонентам в базе телеком-оператора и несколько классов клиентов:\n",
    "\n",
    "* класс `0` - пользователь платит много\n",
    "* класс `1` - пользователь платит мало\n",
    "* класс `2` - пользователь ушёл в отток (не платит ничего)\n",
    "\n",
    "От нас требуется обучить модель классификации на три класса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для визуализации данных выполним понижение размерности с помощью t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "x_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "colors = ['bo', 'gx', 'ro']; num_labels = len(colors)\n",
    "# И нарисуем получившиеся точки в нашем новом пространстве\n",
    "for name, label, color in [('class_%d' % i, i, colors[i]) for i in range(num_labels)]:\n",
    "    plt.plot(x_tsne[y == label, 0], x_tsne[y == label, 1], color, label=\"class %d\" % label)\n",
    "plt.legend(loc=0); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бизнесу требуется построить классификатор клиентов - давате обучим простенький классификатор, основанный на решающем дереве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У объекта под номером 4 класс 2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# выбираем рандомный объект\n",
    "\n",
    "num_objects = X.shape[0]\n",
    "random_id = np.random.randint(num_objects)\n",
    "\n",
    "# преобразуем фичи, чтобы подошли на вход модели и делаем предсказания\n",
    "test_object = X[random_id,:].reshape(1, -1)\n",
    "pred = clf.predict(test_object)\n",
    "print(f\"У объекта под номером {random_id} класс {pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гототово, у нас есть модель, которая что-то обучает и что-то предсказывает. Можем сериализовать её для дальнейшего использования c помощью `pickle`. А теперь попробуем обернуть в докер наш пайплан обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый контейнер для сервиса я взял отсюда: https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/ . Он включает python 3.5 и библиотеки numpy и sklearn - больше нам для обучения модели ниего не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск сборки\n",
    "<pre>\n",
    " docker build . -f Dockerfile -t mai_service:latest\n",
    "</pre>\n",
    "Запуск обучения модели - см. файл `train.py`\n",
    "<pre>\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data mai_service:latest train_model\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск микросервиса - см. в файле `service.py`\n",
    "<pre>\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data -p 5000:5000 mai_service:latest start_service\n",
    "</pre>\n",
    "Увидеть запущенный контейнер можно через Docker ps\n",
    "<pre>\n",
    "docker ps\n",
    "CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
    "c9ba7303712c        skillbox_service:latest   \"docker-entrypoint.s…\"   14 hours ago        Up 14 hours         0.0.0.0:5000->5000/tcp   infallible_easley\n",
    "</pre>\n",
    "\n",
    "Чтобы проверить, что сервис \"жив\" и способен принимать запросы откройте в браузере спициальную страничку `http://0.0.0.0:5000/ping/` - это т.н. *healh check* нашего сервиса. В браузере должно появится\n",
    "<pre>\n",
    "{\"message\": \"pong\"}\n",
    "</pre>\n",
    "\n",
    "Хороший туториал по [упаковке моделей в контейнеры](https://towardsdatascience.com/deploying-machine-learning-models-with-docker-5d22a4dacb5). Там можно почитать, как скейлить нагрузку помощью nginx+gunikorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем датасете три фичи - нам нужно передать их в наш микросервис. Передавать фичи можно через GET-запросы, например, так:\n",
    "<pre>\n",
    "http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
    "</pre>\n",
    "\n",
    "Дальше нам нужно перехватить их на стороне сервиса, обработать фичи, загрузив в классификатор и выдать ответ:\n",
    "<pre>\n",
    "{\"x1\": 1.0, \"x2\": -2.2, \"x3\": 1.05, \"predicted_class\": 0}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "После окончания работ контейнер можно остановить\n",
    "<pre>\n",
    "docker stop c9ba7303712c\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы упаковали модель в докер и можем использовать модель как микросервис"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим все наши знания о микросервисах в одной картинке\n",
    "\n",
    "* у микросервиса должен быть определён формат ответа в виде JSON схемы\n",
    "* Consul - это сервис, который автоматически дёргает *health check* и рестартует контейнер, если он перестал отвечать\n",
    "* блок `logs` - это Elastic+Logstash+Kibana, связка используется для хранения логов\n",
    "* технические метрики отправляются в хранилище Prometheus и визуализируются  в Grafana. Нотификации в случае нештатных ситуаций отправляются в Slack\n",
    "* инциденты в виде 500-х ошибок отправляются в Sentry для дальнейшего анализа\n",
    "\n",
    "![microservice.png](img/microservice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: применяем t-sne\n",
    "\n",
    "Модифицируйте файл *train.py* - добавьте в пайплайн обучения модели сжатие размерности до *n_components=2* с помощью t-sne и обучите модель **в докере** на \"сжатых данных\". Сохраните полученный объект `tsne_tansformer.pkl`, который умеет выполнять это задание.\n",
    "\n",
    "Решением домашки считается модифицированный файл *train.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: трансформация входных фичей на лету\n",
    "\n",
    "Модифицируйте файл `service.py`: добавьте загрузку объекта для трансформации `tsne_tansformer.pkl` и применяйте её **в докере** для трансформации набора входных фич в сжатые:\n",
    "<pre>\n",
    "[x1, x2, x3] -> [x1_tsne, x2_tsne]\n",
    "</pre>\n",
    "\n",
    "Соответственно, predict надо выполнять на *сжатых* фичах\n",
    "\n",
    "\n",
    "Решением домашки считается модифицированный файл *service.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Используем Flask\n",
    "\n",
    "Перепишите сервис на использование Flask. Вы можете взять готовый базовый образ с Flask, либо добавить установку в тот контейнер, который есть - это нужно сделать в Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML в проде: рекомендательные системы\n",
    "\n",
    "Рекомендательные системы - это обобщённое название для сервисов, которые в ответ на запрос формируют из огромной коллекции доступных сущностей (мы будем называть их \"документами\", англ. item но в реальной жизни это фильмы в онлайн-кинотеатре или товары в интернет-магазине, а саму такую коллекцию документов для краткости будем называть каталогом) некоторый шорт-лист, который будет наиболее подходящим для данного запроса (такие документы называются \"релевантными\"). Рекомендательные системы используют для решения своих задач другие алгоритмы ML.\n",
    "О том, как на основе уже изученных ML-алгоритмов научиться решать задачу поиска релевантных объектов мы поговорим в этом  уроке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы: цели и задачи\n",
    "\n",
    "Основная задача рекомендательной системы - нарезать шорт-лист из каталога, который будет максимально подходить к контексту, в котором запрашиваются рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под \"контекстом\" мы понимаем различные параметры мира, который окружает рекомендательную систему:\n",
    "\n",
    "* с какими документами из каталога уже взаимодействовал пользователь\n",
    "* какова \"сила\" взаимодействия - лайк или дизлайк? Если оценка - то какая? Если просмотр фильма - то как долго смотрел?\n",
    "* в какой стране находится пользователь - в Казахстане смотрят фильм \"Рэкетир\" а в России \"Бумер\".\n",
    "* утро или вечер в момент посмотрения рекомендаций\n",
    "* что по соцдему - какого пола и возраста пользователь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача рекомендаций представляет собой задачу *ранжирования* - мы пытаемся расставить контент в таком порядке, чтобы в начале списка был самый релевантный контент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, например, как выглядит главная страница ivi - по сути, это персонализованная нарезка из доступного каталога контента\n",
    "\n",
    "![ivi_main](img/ivi_catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Различают два вида рекомендаций:\n",
    "\n",
    "* *content to user*  строятся на основе фидбэка, полученного от пользователя (например, лайкнутые фильмы)\n",
    "* *content to content* строятся на основе свойств контента найти максимально похожие на него элементы (например, блок \"С этим часто покупают\" на Ozon)\n",
    "\n",
    "Рекомендательная система решает задачу персонализации сервиса - это значит, что каждый пользователь  видит свой вариант сервиса - можно сказать, что у вас появляется столько вариантов наполнения страниц вашего сайта, сколько у вас пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендательные системы нужны в ситуации, когда пользователь не может сделать выбор из огромного количества возможных вариантов каталога (например, каталога интернет-магазина) и ему нужно как-то помочь, ограничив выбор узким кругом объектов, которые больше всего подходят к текущему контексту - такие объекты и называются *релевантными*. Избавив пользователя от необходимости просматривать огромное число неподходящих объектов, рекомендательная система позволяет быстрее сконвертировать пользовательскую сессию в \"целевое действие\" - просмотр фильма или покупку гаджета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два основных метода для поиска релелевантных объектов\n",
    "\n",
    "* collaborative filtering\n",
    "* content filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели *коллаборативной фильтрации* используют интуитивное предположение о том, что если у двух пользователей сильно пересекаются два множества контента (с которым они взаимодействовали) то у этих двух пользователей схожие вкусы - на основе этого можно делать рекомендации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть информация о пользователях `X, Y, Z` и фильмах `A, B, C, D, E`. В таблице символ \"+\" означает, что пользователь $i$ смотрел фильм $j$:\n",
    "\n",
    "| - | A | B | C | D | E |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| X  | +  | -  | +  | +  | -  |\n",
    "| Y  | -  | +  | -  | -  | +  |\n",
    "| Z  | +  | +  | -  | +  | -  |\n",
    "\n",
    "Как видно, пользователи `X, Z` очень похожи друг на друга, т.к. им обоим нравится фильмы \"А\" и \"D\".\n",
    "\n",
    "В то же время пользователь `Y` не похож на них, он смотрит другие фильмы. Из картинки видно, что если бы нам нужно было бы построить персональные рекомендации для пользователя `X`, то мы бы порекомендовали  ему фильм `B` - такой фильм смотрел пользователь Z и значит, этот фильм понравится пользователю X, потому что данные говорят о том, чт вкусы этих двух пользователей похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Content-based* фильтрация подбирает похожие элементы на основе свойств контента. Например, в случае фильма его свойства - это актёр, режиссёр, жанр, место действия и т.д. Например, если у нас естьфильм со Стэтхемом, то максимально похожим будет, скорее всего, другой фильм со Стэтхэмом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выделяют *гибридные* рекомендательные системы - в этом случае рекомендации из нескольких моделей (например, `content based` + `collaborative filterig`) используются для формирования итогового ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативные модели обучаются на триплетах (тройках) `(user, item, feedback)`, где для каждой пары `(user, item)` фидбэк может быть двух видов:\n",
    "\n",
    "* explicit (явный)\n",
    "* implicit (неявный)\n",
    "\n",
    "*Явный фидбэк* - это любое явное выражение пользователем своего отношения к контенту: лайк, оценка и т.д. *Неявный фидбэк* - это длительность просмотра фильма, количество заходов на карточку товара, время чтения статьи и т.д.: интуитивно понятно, что если пользователь смотрит фильм долго - то такой фильм, скорее всего, ему нравится, но явного сигнала (например, в виде лайка) мы не получаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача построения рекомендации решается с помощью классических алгоритмов машинного обучения:\n",
    "\n",
    "* метод ближайших соседей (knn)\n",
    "* матричная факторизация\n",
    "* логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендатель отдаёт отранжированный список объектов. На этот список обычно накладываются разнообразные бизнес-правила, позволяющие оптимизировать метрики, важные для бизнеса: например, искуственное повышение новинок в выдаче.\n",
    "\n",
    "Грамотно построенная рекомендательная система позволяет нарастить продуктовые метрики. Например, в онлайн-кинотеатре:\n",
    "\n",
    "* растёт конверсия в просмотр т.к. пользователь получает на главной странице самый подходящий контент\n",
    "* увеличивается длительности смотрения на пользователя, удачно рекомендованный сериал генерирует десятки часов смотрения\n",
    "* уменьшается отток с сервиса - пользователь за одну сессию может выбрать несколько фильмов, которые будет смотреть несколько заходов подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN рекомендации\n",
    "\n",
    "Мы попробуем построить простейшую модель коллаборативной фильтрации, пользуясь только информацией оп просмотрах контента в онлайн-кинотеатре ivi.\n",
    "\n",
    "Загрузим исходные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.csv', delimiter=',', header=0,\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим дополнительную информацию о контенте: жанры, дату появления на сервисе, рейтинг кинопоиска и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "\n",
       "       genre  \n",
       "0  Для детей  \n",
       "1  Для детей  \n",
       "2  Для детей  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.csv', delimiter=',', header=0,\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "\n",
    "content_description.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем разреженную матрицу user-item такую, что\n",
    "\n",
    "* количество строк матрицы совпадает с числом пользователей\n",
    "* количество столбцов матрицы совпадает с количеством контента\n",
    "* на пересечении столбца $i$ и строки $j$ стоит единица, если пользователь $i$ смотрел контент $j$, иначе - ноль\n",
    "\n",
    "Для начала перейдём от индекса контента и индекса пользователя к индексам в разреженной матрице - воспользуемся `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть колонки `user_index, item_index`, которые соответствуют номерам строки и столбца соответственно в матрице user-item. Передадим полученные колонки в конструктор `csr_matrix`, чтобы получить разреженную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на валидацию и контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки 1600 пользователей, размер валидационной выборки 400 пользователей\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"Размер обучающей выборки %d пользователей, размер валидационной выборки %d пользователей\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в наше матрице 2000 пользователей и 27012 единиц контента, у матрицы высокая разреженность - менее 1% ненулевых элементов, остальное заполнено нулями.\n",
    "\n",
    "Чтобы строить рекомендации по колаборативной модели, нам нужен быстрый способ поиска пользователей, у которых схожая история просмотров- наше предположение в том, что похожие пользователи имеют похожую историю просмотров. Для поиска схожих пользователей воспользуемся поиском ближайших соседей по нашей матрице `user-item`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=-1, n_neighbors=20, p=2, radius=1.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "model_knn.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейший класс, который умеет искать похожих по истории смотрения пользователей и выдавать рекомендации. Рекомендации - это контент, который смотрели ближашие соседи пользователя, а сам пользователь этот контент не видел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeFilteringKNNRecommender:\n",
    "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
    "        self.knn_model = knn_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.top_recs = 50\n",
    "    \n",
    "    def make_recs(self, user_history: csr_matrix):\n",
    "        neighbors = model_knn.kneighbors(\n",
    "            random_user_history,\n",
    "            self.num_neighbors,\n",
    "            return_distance=False\n",
    "        )[0]\n",
    "        full_recs = user_item[neighbors,:].max(axis=0)\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        user_history_ids = user_history.nonzero()[1]\n",
    "        # последовательность id того контента, который смотрели ближайшие соседи\n",
    "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
    "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
    "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
    "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
    "        \n",
    "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
    "\n",
    "\n",
    "# объект рекомендателя\n",
    "recommender = ColaborativeFilteringKNNRecommender(\n",
    "    knn_model=model_knn,\n",
    "    user_item_matrix=user_item,\n",
    "    num_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем рекомендатель для случайного пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число успешных рекомендаций 26\n",
      "user_index 916, history: [222 223 225 229 230 231 232 233 234 235]\n",
      "recommendations: [  0   2   5   6   7   8  79  94  95 122]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = recommender.make_recs(random_user_history)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод `similar_items` для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили простейшую рекомендательную систему, основанную на колаборативной фильтрации и поиске ближайших соседей. В следующем уроке мы узнаем, как перейти от рекомендаций основанных на knn к более сложной концепции эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Эмбеддинги пользователей и контента (скрытые факторы)\n",
    "\n",
    "Рекомендации, которые строятся на основе KNN, имеют следующий недостаток: фактическим мы запоминаем матрицу `user-item` на этапе тренировки модели - такие модели называются *memory-based*. Это привобдит к большому расходу памяти на этапе получения предсказаний, т.к. по каждому пользователю мы вынуждены хранить разреженный вектор большой размерности. При росте количества пользователей модель начинает критически быстро расти по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход заключается в применении матричного разложения - когда мы пытаемся приблизить нашу большую разреженную матрицу user-item размерности $m\\times n$ двумя плотными матрицами, которые называются матрицей латентных (скрытых) факторов пользователей размерности $m\\times f$ и матрицей скрытых факторов контента размерности $n \\times f$. О таких методах мы уже говорили в уроке по теме \"Снижение размерности\" курса \"Машинное обучение. Начальный уровень\". Такой подход, при котором мы запоминаем не матрицу user-item, а только некий полезный сигнал из этой матрицы, называется *model-based*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фокус в том, что $m,n$ - это числа порядка десятков тысяч, а $f$ имеет небольшую размерность (обычно 30-50). Кажому пользователю и каждой единице понтента при таком подходе ставится в соответствие вектор размерности $f$, а произведение вектора пользователя $p_u$ на вектор контента $q_i$ даёт единственное число $r_{ui}$ - меру \"релевантности\", насколько данный контент понравится данному пользователю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svd_decomp](img/svd_decomp.png)\n",
    "\n",
    "$$\n",
    "r_{ui} = q_i^Tp_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для матричного разложения используются различные алгоритмы:\n",
    "\n",
    "* Singular Vector Decomposition (SVD)\n",
    "* Alternative Least Squares (ALS)\n",
    "* Bayesian personalized ranking (BPR)\n",
    "\n",
    "При решении реальных задач советую начать с BPR - он даёт отличные результаты, но у него есть и недостаток - вычислительная сложность, которая увеличивает время обучения.\n",
    "\n",
    "Выбирая между SVD и ALS я рекомендую выбирать ALS, т.к. он более новый и более быстрый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы продемонстрируем работу рекомендательной системы на примере SVD-разложения - для этотго даже не нужно устанавливать дополнительные пакеты, нужная функция есть прямо в пакете `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 27012) (2000, 50) (2000, 50)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "latent_factors_num = 50\n",
    "# раскладываем Useк-Item матрицу\n",
    "user_factors, scale, item_factors = svds(\n",
    "    user_item.asfptype(),\n",
    "    k=latent_factors_num,\n",
    "    return_singular_vectors=True\n",
    ")\n",
    "scale = np.diag(np.sqrt(scale))\n",
    "# эмбеддинги пользователей\n",
    "user_factors = np.dot(user_factors, scale).astype(np.float32)\n",
    "# эмбеддинги контента\n",
    "item_factors = np.dot(scale, item_factors).astype(np.float32)\n",
    "\n",
    "print(user_item.shape, user_factors.shape, user_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем класс, который будет формировать рекомендации на основе матриц `user_factors` и `item_factors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9601, 13841,  9612,  9613,  9630,  9611,  9614,  9603,  9598,\n",
       "        9599,  9605,  9594,  9615,  9600,  9602, 16421,  9616,  9634,\n",
       "        9633,  9606])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColaborativeFilteringFactorizationRecommender:\n",
    "    def __init__(self, user_factors, item_factors, user_item_matrix):\n",
    "        self.user_factors = user_factors\n",
    "        self.item_factors = item_factors\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "    \n",
    "    def make_recs(self, user_index):\n",
    "        user_factors = self.user_factors[user_index,:]\n",
    "        user_history_ids = self.user_item_matrix.getrow(user_index).nonzero()[1]\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        personal_scores = user_factors.reshape(1, -1).dot(self.item_factors).flatten()\n",
    "        personal_recs = np.argsort(-personal_scores)[:20]\n",
    "        \n",
    "        return np.array([i for i in personal_recs if i not in user_history_ids])\n",
    "\n",
    "factorization_recommender = ColaborativeFilteringFactorizationRecommender(\n",
    "    user_factors=user_factors,\n",
    "    item_factors=item_factors,\n",
    "    user_item_matrix=user_item\n",
    ")\n",
    "\n",
    "factorization_recommender.make_recs(random_user_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативная модель на основе скрытых факторов пользователя/контента позволяет быстро получить список релевантного контента для каждого пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этому уроке мы поговорили о том, как перейти от memory-based рекомендателям к model-based. В следующем уроке обсудим, а как измеряют эффективность рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики рекомендательных систем\n",
    "\n",
    "Мы научились делать персональные рекомендации единиц каталога. В этом уроке поговорим о том, как отделить \"хорошие\" модели от \"плохих\"\n",
    "\n",
    "Метрики рекомендательной системы (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* продуктовые (бизнес) метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продуктовые метрики - это то, как пользователи реагируют на рекомендации. К пользовательским метрикам можно отнести:\n",
    "\n",
    "* конверсию (в просмотр, в покупку и т.д.) - чем выше конверсия, тем лучше модель \n",
    "* длительность нахождения на сервисе (чем дольше, тем лучше)\n",
    "* поизицию, до которой были просмотрены рекомендации - чем меньше позиций пролистали, тем лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Продуктовые метрики** (иногда их называют онлайн-метриками) можно измерить, только проведя АБ-тест, эксперимент на реальных пользователях сервиса. Механика проведения эксперимента следующая мы делим пользователей на две группы: группа А видит старый вариант алгоритма, группа Б - новый вариант. После окончания теста сравнивается значение в тестовой группе и контрольной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оффлайн-метрики** рекомендательных систем позволяют проверить, насколько качественные прогнозы выполняет модель, пользуясь историческими данными.\n",
    "\n",
    "Для этой задачи можно приспособить известную Вам метрику **RMSE**, которая определяет, насколько точно мы приблизили матрицу *user-item*\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(a_{ij}-\\hat{a}_{ij})^2}\n",
    "$$\n",
    "\n",
    "Где $a_{ij}$ - истинное значение фидбека пользователя $i$ для контента $j$, а $\\hat{a}_{ij}$ - значение фидбэка, которое предсказала наша модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это неплохая метрика, например, для задачи регрессии, но для рекомендаций она немного странная - в принципе, нам не важно, насколько хорошо предсказываются оценки 2,3,4 - мы хотим уверенном предсказывать высокие оценки: 8,9,10.\n",
    "\n",
    "Другой пример метрик - это метрики из задач классификации (precision + reccall).\n",
    "\n",
    "Допустим, у нас есть список рекомендаций из $n=5$ элементов и список фактических просмотров из $k=3$ элементов. В красную рамку обведены те рекомендации, которые были фактически просмотрены - количество таких фильмов $m = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eval](img/eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**  показывает отношение товаров, купленных из рекомендаций к общему числу фактических просмотров\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{m}{k} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "**Precision**  показывает, насколько много из рекомендованного нами попало в итоге в просмотренное\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{m}{n} = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "У precision заметен один недостаток - игнорируется порядок, в котором пользователя заинтересовали рекомендованные объекты. Эту задачу решает метрика *average precision at K*. В числителе дисконтируем каждую \"единичку\", на ту позицию, где она стоит:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{ap} = \\frac{1}{5}\\left( 0 + \\frac{1}{2} + \\frac{1}{3}\\right) = \\frac{1}{5}\\cdot \\frac{5}{6} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "при такой модификации мы заставляем модель не просто угадывать релевантные объекты, но и \"поднимать\" их выше к началу списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме перечисленных выше метрик, которые измеряют точность \"угадывания\", можно мерять и другие показатели\n",
    "\n",
    "* diversity (разннообразие выдачи) - как сильно в выдаче представлены разные жанры, авторы и т.д.\n",
    "* coverage (покарытие каталога) - какая часть каталога покрывается рекомендациями (следует избегать случаев, когда всем пользователям рекомендуюется одно и то же подмножество)\n",
    "* serendipity (индивидуальность) -  берем разницу между вероятностью рекомендации айтема юзеру и всем юзерам (т.е. насколько рекомендация индивидуальна) и суммируем по всем релевантным рекомендованым айтемам. Позволяет определить, насколько выдача \"заточена\" под польователя\n",
    "* novelty (новизна) - как часто попадают в выдачу новые (холодные) элементы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание на метрики\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "# --- ВАШ КОД ТУТ ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке познакомились с метриками. Теперь вы можете отличать хорошие модели рекомендаций от плохих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы мознакомились с темой рекомендательных систем. Это область знаний, которую \"просто выучить, сложно понять\" - потому что с помощью простых алгоритмов ML можно сильно увеличить эффективность вашего бизнеса, но правильное применение этих методов к задаче построения рекомендательной системы - особое искусство, требующее хорошего понимания бизнес-области и знания специфических метрик систем ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
